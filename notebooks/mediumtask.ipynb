{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2e8c381",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs: 79\n",
      "Columns: ['name', 'url', 'artist', 'title', 'genre', 'license_type', 'language', 'lyric_overlap', 'polyphonic', 'non_lexical', 'text', 'lines', 'words', 'file_name'] ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>license_type</th>\n",
       "      <th>language</th>\n",
       "      <th>lyric_overlap</th>\n",
       "      <th>polyphonic</th>\n",
       "      <th>non_lexical</th>\n",
       "      <th>text</th>\n",
       "      <th>lines</th>\n",
       "      <th>words</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HILA_-_Give_Me_the_Same</td>\n",
       "      <td>https://www.jamendo.com/track/1559261/give-me-...</td>\n",
       "      <td>HILA</td>\n",
       "      <td>Give Me The Same</td>\n",
       "      <td>Pop</td>\n",
       "      <td>BY-ND</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>lay awake at night\\nwondering how could i\\nlet...</td>\n",
       "      <td>[{'start': 18.6199798584, 'end': 19.8730163574...</td>\n",
       "      <td>[{'start': 18.6199798584, 'end': 18.8935203552...</td>\n",
       "      <td>subsets/en/mp3/HILA_-_Give_Me_the_Same.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quentin_Hannappe_-_Keep_On</td>\n",
       "      <td>https://www.jamendo.com/track/1552064/keep-on</td>\n",
       "      <td>Quentin Hannappe</td>\n",
       "      <td>Keep On</td>\n",
       "      <td>Pop</td>\n",
       "      <td>BY-NC-ND</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>keep on working on your dreams and don't run a...</td>\n",
       "      <td>[{'start': 10.1839199066, 'end': 14.5356912613...</td>\n",
       "      <td>[{'start': 10.1839199066, 'end': 10.4235830307...</td>\n",
       "      <td>subsets/en/mp3/Quentin_Hannappe_-_Keep_On.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name  \\\n",
       "0     HILA_-_Give_Me_the_Same   \n",
       "1  Quentin_Hannappe_-_Keep_On   \n",
       "\n",
       "                                                 url            artist  \\\n",
       "0  https://www.jamendo.com/track/1559261/give-me-...              HILA   \n",
       "1      https://www.jamendo.com/track/1552064/keep-on  Quentin Hannappe   \n",
       "\n",
       "              title genre license_type language  lyric_overlap  polyphonic  \\\n",
       "0  Give Me The Same   Pop        BY-ND       en          False       False   \n",
       "1           Keep On   Pop     BY-NC-ND       en          False       False   \n",
       "\n",
       "   non_lexical                                               text  \\\n",
       "0        False  lay awake at night\\nwondering how could i\\nlet...   \n",
       "1        False  keep on working on your dreams and don't run a...   \n",
       "\n",
       "                                               lines  \\\n",
       "0  [{'start': 18.6199798584, 'end': 19.8730163574...   \n",
       "1  [{'start': 10.1839199066, 'end': 14.5356912613...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [{'start': 18.6199798584, 'end': 18.8935203552...   \n",
       "1  [{'start': 10.1839199066, 'end': 10.4235830307...   \n",
       "\n",
       "                                       file_name  \n",
       "0     subsets/en/mp3/HILA_-_Give_Me_the_Same.mp3  \n",
       "1  subsets/en/mp3/Quentin_Hannappe_-_Keep_On.mp3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "DATA_ROOT = Path(r\"C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_full\")  # <-- change to your downloaded folder\n",
    "META_JSONL = DATA_ROOT / \"metadata.jsonl\"\n",
    "\n",
    "assert META_JSONL.exists(), f\"metadata.jsonl not found at: {META_JSONL}\"\n",
    "\n",
    "rows = []\n",
    "with META_JSONL.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rows.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(\"Songs:\", len(df))\n",
    "print(\"Columns:\", list(df.columns)[:20], \"...\")\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ec73b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has 'text'? True\n",
      "Has 'lines'? True\n",
      "Has 'words'? True\n",
      "Language counts:\n",
      " language\n",
      "en    20\n",
      "de    20\n",
      "es    20\n",
      "fr    19\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Example lines[0]:\n",
      "[{'start': 18.6199798584, 'end': 19.8730163574, 'text': 'lay awake at night'}, {'start': 20.8442592621, 'end': 22.1282539368, 'text': 'wondering how could i'}]\n"
     ]
    }
   ],
   "source": [
    "# Check what fields exist\n",
    "print(\"Has 'text'?\", \"text\" in df.columns)\n",
    "print(\"Has 'lines'?\", \"lines\" in df.columns)\n",
    "print(\"Has 'words'?\", \"words\" in df.columns)\n",
    "print(\"Language counts:\\n\", df[\"language\"].value_counts() if \"language\" in df.columns else \"No language column\")\n",
    "\n",
    "# Look at a sample \"lines\" entry\n",
    "if \"lines\" in df.columns:\n",
    "    print(\"\\nExample lines[0]:\")\n",
    "    print(df.loc[0, \"lines\"][:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa95b734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected keys: start end text\n",
      "Segments created: 2924\n",
      "Bad songs skipped: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seg_path</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...</td>\n",
       "      <td>i thought we could get better</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...</td>\n",
       "      <td>stayed committed like a soldier</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...</td>\n",
       "      <td>now i know that you don't care at all</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...</td>\n",
       "      <td>gave all of my soul and my heart to someone th...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...</td>\n",
       "      <td>i was a fool to believe that you would finally...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            seg_path  \\\n",
       "0  C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...   \n",
       "1  C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...   \n",
       "2  C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...   \n",
       "3  C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...   \n",
       "4  C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_f...   \n",
       "\n",
       "                                              lyrics language  \n",
       "0                      i thought we could get better       en  \n",
       "1                    stayed committed like a soldier       en  \n",
       "2              now i know that you don't care at all       en  \n",
       "3  gave all of my soul and my heart to someone th...       en  \n",
       "4  i was a fool to believe that you would finally...       en  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "SR = 22050\n",
    "MIN_DUR = 1.5     # seconds: skip tiny lines\n",
    "MAX_DUR = 6.0     # seconds: cap long lines\n",
    "MAX_SONGS = None  # set like 50 to speed up first run\n",
    "\n",
    "out_seg_dir = DATA_ROOT / \"medium_segments_wav\"\n",
    "out_seg_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def pick_keys(example_line: dict):\n",
    "    # Try common key names seen in versions of the dataset\n",
    "    start_keys = [\"start_time\", \"start\", \"t_start\"]\n",
    "    end_keys   = [\"end_time\", \"end\", \"t_end\"]\n",
    "    text_keys  = [\"lyrics_line\", \"line\", \"text\"]\n",
    "    def find_key(cands):\n",
    "        for k in cands:\n",
    "            if k in example_line:\n",
    "                return k\n",
    "        return None\n",
    "    return find_key(start_keys), find_key(end_keys), find_key(text_keys)\n",
    "\n",
    "# Detect keys from first non-empty lines entry\n",
    "start_k = end_k = text_k = None\n",
    "for x in df[\"lines\"]:\n",
    "    if isinstance(x, list) and len(x) > 0 and isinstance(x[0], dict):\n",
    "        start_k, end_k, text_k = pick_keys(x[0])\n",
    "        break\n",
    "\n",
    "print(\"Detected keys:\", start_k, end_k, text_k)\n",
    "assert start_k and end_k and text_k, \"Could not detect line start/end/text keys. Paste df.loc[0,'lines'][:2] to fix.\"\n",
    "\n",
    "seg_rows = []\n",
    "bad = 0\n",
    "\n",
    "song_iter = df.itertuples(index=False)\n",
    "if MAX_SONGS:\n",
    "    song_iter = list(song_iter)[:MAX_SONGS]\n",
    "\n",
    "for i, ex in enumerate(song_iter):\n",
    "    exd = ex._asdict()\n",
    "\n",
    "    lang = exd.get(\"language\", \"unknown\")\n",
    "    lines = exd.get(\"lines\", [])\n",
    "\n",
    "    # audio path field is commonly \"file_name\" (relative to metadata.jsonl)\n",
    "    # Your README says: subsets/*/mp3/*.mp3\n",
    "    rel_audio = exd.get(\"file_name\") or exd.get(\"audio\") or exd.get(\"path\")\n",
    "    if rel_audio is None:\n",
    "        bad += 1\n",
    "        continue\n",
    "\n",
    "    audio_path = (META_JSONL.parent / rel_audio).resolve()\n",
    "    if not audio_path.exists():\n",
    "        bad += 1\n",
    "        continue\n",
    "\n",
    "    # Lyrics text for embedding per-segment will come from each line; but keep full song text if needed\n",
    "    try:\n",
    "        y, _ = librosa.load(str(audio_path), sr=SR, mono=True)  # requires ffmpeg backend for mp3\n",
    "    except Exception as e:\n",
    "        print(\"Audio load failed:\", audio_path.name, \"->\", e)\n",
    "        bad += 1\n",
    "        continue\n",
    "\n",
    "    if not isinstance(lines, list) or len(lines) == 0:\n",
    "        continue\n",
    "\n",
    "    for j, ln in enumerate(lines):\n",
    "        try:\n",
    "            start = float(ln[start_k])\n",
    "            end   = float(ln[end_k])\n",
    "            text  = str(ln[text_k]).strip()\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        dur = end - start\n",
    "        if dur < MIN_DUR:\n",
    "            continue\n",
    "        if dur > MAX_DUR:\n",
    "            end = start + MAX_DUR\n",
    "\n",
    "        s0, s1 = int(start * SR), int(end * SR)\n",
    "        seg = y[s0:s1]\n",
    "        if len(seg) < int(MIN_DUR * SR):\n",
    "            continue\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        seg_name = f\"song{i:03d}_line{j:03d}_{lang}.wav\"\n",
    "        seg_path = out_seg_dir / seg_name\n",
    "        sf.write(str(seg_path), seg, SR, subtype=\"PCM_16\")\n",
    "\n",
    "        seg_rows.append({\"seg_path\": str(seg_path), \"lyrics\": text, \"language\": lang})\n",
    "\n",
    "seg_meta = pd.DataFrame(seg_rows)\n",
    "seg_meta.to_csv(DATA_ROOT / \"segment_meta.csv\", index=False)\n",
    "\n",
    "print(\"Segments created:\", len(seg_meta))\n",
    "print(\"Bad songs skipped:\", bad)\n",
    "seg_meta.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa7e061a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_audio shape: (2924, 1, 128, 256)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "seg_meta = pd.read_csv(DATA_ROOT / \"segment_meta.csv\")\n",
    "\n",
    "N_MELS = 128\n",
    "N_FFT = 2048\n",
    "HOP = 512\n",
    "T_FIXED = 256   # time frames (pad/crop)\n",
    "\n",
    "def logmel_fixed(path):\n",
    "    y, _ = librosa.load(path, sr=SR, mono=True)\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=SR, n_mels=N_MELS, n_fft=N_FFT, hop_length=HOP)\n",
    "    x = librosa.power_to_db(mel, ref=np.max).astype(np.float32)  # (128, T)\n",
    "\n",
    "    if x.shape[1] < T_FIXED:\n",
    "        x = np.pad(x, ((0,0),(0, T_FIXED - x.shape[1])))\n",
    "    else:\n",
    "        x = x[:, :T_FIXED]\n",
    "\n",
    "    x = (x - x.mean()) / (x.std() + 1e-6)\n",
    "    return x[None, :, :]  # (1, 128, 256)\n",
    "\n",
    "# Option: start smaller for speed\n",
    "MAX_SEGS = 3000  # increase later if you want\n",
    "seg_meta_small = seg_meta.sample(n=min(MAX_SEGS, len(seg_meta)), random_state=42).reset_index(drop=True)\n",
    "\n",
    "X_audio = np.stack([logmel_fixed(p) for p in seg_meta_small[\"seg_path\"]], axis=0)\n",
    "np.save(DATA_ROOT / \"X_audio.npy\", X_audio)\n",
    "seg_meta_small.to_csv(DATA_ROOT / \"segment_meta_used.csv\", index=False)\n",
    "\n",
    "print(\"X_audio shape:\", X_audio.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df6eeebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E64 shape: (2924, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "seg_meta_used = pd.read_csv(DATA_ROOT / \"segment_meta_used.csv\")\n",
    "texts = seg_meta_used[\"lyrics\"].astype(str).tolist()\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "E = tfidf.fit_transform(texts).toarray().astype(np.float32)\n",
    "\n",
    "pca = PCA(n_components=64, random_state=42)\n",
    "E64 = pca.fit_transform(E).astype(np.float32)\n",
    "\n",
    "np.save(DATA_ROOT / \"E64.npy\", E64)\n",
    "print(\"E64 shape:\", E64.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9da38333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n",
      "epoch 01 loss 0.6642\n",
      "epoch 05 loss 0.3044\n",
      "epoch 10 loss 0.2707\n",
      "epoch 15 loss 0.2577\n",
      "epoch 20 loss 0.2550\n",
      "epoch 25 loss 0.2517\n",
      "Z_audio: (2924, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_audio = np.load(DATA_ROOT / \"X_audio.npy\")  # (N,1,128,256)\n",
    "E64 = np.load(DATA_ROOT / \"E64.npy\")          # (N,64)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", device)\n",
    "\n",
    "class ConvVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=32):\n",
    "        super().__init__()\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 4, 2, 1), nn.ReLU(),   # (16,64,128)\n",
    "            nn.Conv2d(16, 32, 4, 2, 1), nn.ReLU(),  # (32,32,64)\n",
    "            nn.Conv2d(32, 64, 4, 2, 1), nn.ReLU(),  # (64,16,32)\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU()  # (128,8,16)\n",
    "        )\n",
    "        self.flat_dim = 128 * 8 * 16\n",
    "        self.fc_mu = nn.Linear(self.flat_dim, latent_dim)\n",
    "        self.fc_lv = nn.Linear(self.flat_dim, latent_dim)\n",
    "\n",
    "        self.fc_dec = nn.Linear(latent_dim, self.flat_dim)\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),   # (64,16,32)\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(),    # (32,32,64)\n",
    "            nn.ConvTranspose2d(32, 16, 4, 2, 1), nn.ReLU(),    # (16,64,128)\n",
    "            nn.ConvTranspose2d(16, 1, 4, 2, 1)                 # (1,128,256)\n",
    "        )\n",
    "\n",
    "    def reparam(self, mu, lv):\n",
    "        std = torch.exp(0.5 * lv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.enc(x).view(x.size(0), -1)\n",
    "        mu, lv = self.fc_mu(h), self.fc_lv(h)\n",
    "        z = self.reparam(mu, lv)\n",
    "        h2 = self.fc_dec(z).view(x.size(0), 128, 8, 16)\n",
    "        recon = self.dec(h2)\n",
    "        return recon, mu, lv\n",
    "\n",
    "def loss_fn(x, recon, mu, lv):\n",
    "    recon_loss = nn.functional.mse_loss(recon, x, reduction=\"mean\")\n",
    "    kl = -0.5 * torch.mean(1 + lv - mu.pow(2) - lv.exp())\n",
    "    return recon_loss + kl\n",
    "\n",
    "LATENT = 32\n",
    "BATCH = 32\n",
    "EPOCHS = 25\n",
    "LR = 1e-3\n",
    "\n",
    "dl = DataLoader(TensorDataset(torch.from_numpy(X_audio).float()),\n",
    "                batch_size=BATCH, shuffle=True)\n",
    "\n",
    "model = ConvVAE(latent_dim=LATENT).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    tot = 0.0\n",
    "    for (xb,) in dl:\n",
    "        xb = xb.to(device)\n",
    "        recon, mu, lv = model(xb)\n",
    "        loss = loss_fn(xb, recon, mu, lv)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tot += loss.item()\n",
    "    if ep % 5 == 0 or ep == 1:\n",
    "        print(f\"epoch {ep:02d} loss {tot/len(dl):.4f}\")\n",
    "\n",
    "# Extract latent embeddings (mu)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    xb = torch.from_numpy(X_audio).float().to(device)\n",
    "    _, mu, _ = model(xb)\n",
    "    Z_audio = mu.cpu().numpy()\n",
    "\n",
    "np.save(DATA_ROOT / \"Z_audio.npy\", Z_audio)\n",
    "print(\"Z_audio:\", Z_audio.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b191832a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>representation</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>ARI_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio_only</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.488536</td>\n",
       "      <td>0.722215</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_only</td>\n",
       "      <td>agglo</td>\n",
       "      <td>0.493051</td>\n",
       "      <td>0.713936</td>\n",
       "      <td>0.002001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>audio_only</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>0.314143</td>\n",
       "      <td>1.062638</td>\n",
       "      <td>0.002308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>agglo</td>\n",
       "      <td>0.307607</td>\n",
       "      <td>1.076851</td>\n",
       "      <td>0.003368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hybrid</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  representation algorithm  silhouette  davies_bouldin  ARI_language\n",
       "0     audio_only    kmeans    0.488536        0.722215      0.002366\n",
       "1     audio_only     agglo    0.493051        0.713936      0.002001\n",
       "2     audio_only    dbscan         NaN             NaN      0.000000\n",
       "3         hybrid    kmeans    0.314143        1.062638      0.002308\n",
       "4         hybrid     agglo    0.307607        1.076851      0.003368\n",
       "5         hybrid    dbscan         NaN             NaN      0.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, adjusted_rand_score\n",
    "\n",
    "seg_meta_used = pd.read_csv(DATA_ROOT / \"segment_meta_used.csv\")\n",
    "Z_audio = np.load(DATA_ROOT / \"Z_audio.npy\")\n",
    "E64 = np.load(DATA_ROOT / \"E64.npy\")\n",
    "\n",
    "Z_hybrid = np.concatenate([Z_audio, E64], axis=1)\n",
    "np.save(DATA_ROOT / \"Z_hybrid.npy\", Z_hybrid)\n",
    "\n",
    "# Labels for ARI (language)\n",
    "y = seg_meta_used[\"language\"].astype(\"category\").cat.codes.values\n",
    "k = len(np.unique(y))  # number of languages present in your subset\n",
    "\n",
    "def eval_all(Z, labels):\n",
    "    # Handle degenerate cases\n",
    "    if len(set(labels)) < 2:\n",
    "        return None, None\n",
    "    return silhouette_score(Z, labels), davies_bouldin_score(Z, labels)\n",
    "\n",
    "results = []\n",
    "\n",
    "for rep_name, Z in [(\"audio_only\", Z_audio), (\"hybrid\", Z_hybrid)]:\n",
    "    # KMeans\n",
    "    labels = KMeans(n_clusters=k, random_state=42, n_init=\"auto\").fit_predict(Z)\n",
    "    sil, db = eval_all(Z, labels)\n",
    "    ari = adjusted_rand_score(y, labels)\n",
    "    results.append([rep_name, \"kmeans\", sil, db, ari])\n",
    "\n",
    "    # Agglomerative\n",
    "    labels = AgglomerativeClustering(n_clusters=k).fit_predict(Z)\n",
    "    sil, db = eval_all(Z, labels)\n",
    "    ari = adjusted_rand_score(y, labels)\n",
    "    results.append([rep_name, \"agglo\", sil, db, ari])\n",
    "\n",
    "    # DBSCAN (tune eps if needed)\n",
    "    labels = DBSCAN(eps=1.5, min_samples=10).fit_predict(Z)\n",
    "    mask = labels != -1\n",
    "    if mask.sum() > 20 and len(set(labels[mask])) > 1:\n",
    "        sil = silhouette_score(Z[mask], labels[mask])\n",
    "        db = davies_bouldin_score(Z[mask], labels[mask])\n",
    "    else:\n",
    "        sil, db = None, None\n",
    "    ari = adjusted_rand_score(y, labels)\n",
    "    results.append([rep_name, \"dbscan\", sil, db, ari])\n",
    "\n",
    "metrics = pd.DataFrame(results, columns=[\"representation\",\"algorithm\",\"silhouette\",\"davies_bouldin\",\"ARI_language\"])\n",
    "metrics.to_csv(DATA_ROOT / \"medium_metrics.csv\", index=False)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f7085275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 2924 | languages: 4\n",
      "Saved full metrics to: C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_full\\medium_metrics_fixed_full.csv\n",
      "\n",
      "Top 15 rows by ARI_language then silhouette:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>representation</th>\n",
       "      <th>alpha_lyrics</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>params</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>noise_ratio</th>\n",
       "      <th>n_used_for_metrics</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>ARI_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>hybrid_alpha2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.032320</td>\n",
       "      <td>3.468271</td>\n",
       "      <td>0.028714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>hybrid_alpha4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2924</td>\n",
       "      <td>-0.052201</td>\n",
       "      <td>2.627395</td>\n",
       "      <td>0.008992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_only</td>\n",
       "      <td>0.00</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=0.6,min_samples=20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.264022</td>\n",
       "      <td>2152</td>\n",
       "      <td>0.355419</td>\n",
       "      <td>0.873377</td>\n",
       "      <td>0.003882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=2.0,min_samples=5</td>\n",
       "      <td>45</td>\n",
       "      <td>0.219904</td>\n",
       "      <td>2281</td>\n",
       "      <td>-0.148752</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.003484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=1.2,min_samples=5</td>\n",
       "      <td>42</td>\n",
       "      <td>0.678181</td>\n",
       "      <td>941</td>\n",
       "      <td>0.078941</td>\n",
       "      <td>0.846278</td>\n",
       "      <td>0.003282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=1.5,min_samples=20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.650821</td>\n",
       "      <td>1021</td>\n",
       "      <td>0.250339</td>\n",
       "      <td>1.057510</td>\n",
       "      <td>0.003172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=2.0,min_samples=10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.320793</td>\n",
       "      <td>1986</td>\n",
       "      <td>-0.112616</td>\n",
       "      <td>1.056036</td>\n",
       "      <td>0.002913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>hybrid_alpha0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.167494</td>\n",
       "      <td>2.170556</td>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>hybrid_alpha1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.061606</td>\n",
       "      <td>2.772309</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=1.2,min_samples=10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.780096</td>\n",
       "      <td>643</td>\n",
       "      <td>0.156688</td>\n",
       "      <td>1.073230</td>\n",
       "      <td>0.001987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>hybrid_alpha1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=2.0,min_samples=5</td>\n",
       "      <td>45</td>\n",
       "      <td>0.845075</td>\n",
       "      <td>453</td>\n",
       "      <td>0.672217</td>\n",
       "      <td>0.375073</td>\n",
       "      <td>0.001890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=1.5,min_samples=5</td>\n",
       "      <td>43</td>\n",
       "      <td>0.477428</td>\n",
       "      <td>1528</td>\n",
       "      <td>-0.010577</td>\n",
       "      <td>0.856663</td>\n",
       "      <td>0.001764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=1.5,min_samples=10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.575923</td>\n",
       "      <td>1240</td>\n",
       "      <td>0.051524</td>\n",
       "      <td>0.916044</td>\n",
       "      <td>0.001684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hybrid_alpha2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=2.0,min_samples=5</td>\n",
       "      <td>42</td>\n",
       "      <td>0.879275</td>\n",
       "      <td>353</td>\n",
       "      <td>0.832965</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.001675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>hybrid_alpha4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=2.0,min_samples=5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.896375</td>\n",
       "      <td>303</td>\n",
       "      <td>0.907186</td>\n",
       "      <td>0.129356</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       representation  alpha_lyrics algorithm                  params  \\\n",
       "80    hybrid_alpha2.0          2.00    kmeans                     k=4   \n",
       "100   hybrid_alpha4.0          4.00    kmeans                     k=4   \n",
       "4          audio_only          0.00    dbscan  eps=0.6,min_samples=20   \n",
       "37   hybrid_alpha0.25          0.25    dbscan   eps=2.0,min_samples=5   \n",
       "31   hybrid_alpha0.25          0.25    dbscan   eps=1.2,min_samples=5   \n",
       "36   hybrid_alpha0.25          0.25    dbscan  eps=1.5,min_samples=20   \n",
       "38   hybrid_alpha0.25          0.25    dbscan  eps=2.0,min_samples=10   \n",
       "40    hybrid_alpha0.5          0.50    kmeans                     k=4   \n",
       "60    hybrid_alpha1.0          1.00    kmeans                     k=4   \n",
       "32   hybrid_alpha0.25          0.25    dbscan  eps=1.2,min_samples=10   \n",
       "77    hybrid_alpha1.0          1.00    dbscan   eps=2.0,min_samples=5   \n",
       "34   hybrid_alpha0.25          0.25    dbscan   eps=1.5,min_samples=5   \n",
       "35   hybrid_alpha0.25          0.25    dbscan  eps=1.5,min_samples=10   \n",
       "97    hybrid_alpha2.0          2.00    dbscan   eps=2.0,min_samples=5   \n",
       "117   hybrid_alpha4.0          4.00    dbscan   eps=2.0,min_samples=5   \n",
       "\n",
       "     n_clusters  noise_ratio  n_used_for_metrics  silhouette  davies_bouldin  \\\n",
       "80            4     0.000000                2924    0.032320        3.468271   \n",
       "100           4     0.000000                2924   -0.052201        2.627395   \n",
       "4             4     0.264022                2152    0.355419        0.873377   \n",
       "37           45     0.219904                2281   -0.148752        0.969375   \n",
       "31           42     0.678181                 941    0.078941        0.846278   \n",
       "36            3     0.650821                1021    0.250339        1.057510   \n",
       "38           12     0.320793                1986   -0.112616        1.056036   \n",
       "40            4     0.000000                2924    0.167494        2.170556   \n",
       "60            4     0.000000                2924    0.061606        2.772309   \n",
       "32           11     0.780096                 643    0.156688        1.073230   \n",
       "77           45     0.845075                 453    0.672217        0.375073   \n",
       "34           43     0.477428                1528   -0.010577        0.856663   \n",
       "35           12     0.575923                1240    0.051524        0.916044   \n",
       "97           42     0.879275                 353    0.832965        0.200521   \n",
       "117          40     0.896375                 303    0.907186        0.129356   \n",
       "\n",
       "     ARI_language  \n",
       "80       0.028714  \n",
       "100      0.008992  \n",
       "4        0.003882  \n",
       "37       0.003484  \n",
       "31       0.003282  \n",
       "36       0.003172  \n",
       "38       0.002913  \n",
       "40       0.002856  \n",
       "60       0.002442  \n",
       "32       0.001987  \n",
       "77       0.001890  \n",
       "34       0.001764  \n",
       "35       0.001684  \n",
       "97       0.001675  \n",
       "117      0.001633  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best KMeans:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>representation</th>\n",
       "      <th>alpha_lyrics</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>params</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>noise_ratio</th>\n",
       "      <th>n_used_for_metrics</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>ARI_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>hybrid_alpha2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.032320</td>\n",
       "      <td>3.468271</td>\n",
       "      <td>0.028714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>hybrid_alpha4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>-0.052201</td>\n",
       "      <td>2.627395</td>\n",
       "      <td>0.008992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>hybrid_alpha0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.167494</td>\n",
       "      <td>2.170556</td>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>hybrid_alpha1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.061606</td>\n",
       "      <td>2.772309</td>\n",
       "      <td>0.002442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.390761</td>\n",
       "      <td>1.031907</td>\n",
       "      <td>-0.000062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       representation  alpha_lyrics algorithm params  n_clusters  noise_ratio  \\\n",
       "80    hybrid_alpha2.0          2.00    kmeans    k=4           4          0.0   \n",
       "100   hybrid_alpha4.0          4.00    kmeans    k=4           4          0.0   \n",
       "40    hybrid_alpha0.5          0.50    kmeans    k=4           4          0.0   \n",
       "60    hybrid_alpha1.0          1.00    kmeans    k=4           4          0.0   \n",
       "20   hybrid_alpha0.25          0.25    kmeans    k=4           4          0.0   \n",
       "\n",
       "     n_used_for_metrics  silhouette  davies_bouldin  ARI_language  \n",
       "80                 2924    0.032320        3.468271      0.028714  \n",
       "100                2924   -0.052201        2.627395      0.008992  \n",
       "40                 2924    0.167494        2.170556      0.002856  \n",
       "60                 2924    0.061606        2.772309      0.002442  \n",
       "20                 2924    0.390761        1.031907     -0.000062  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Agglo:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>representation</th>\n",
       "      <th>alpha_lyrics</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>params</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>noise_ratio</th>\n",
       "      <th>n_used_for_metrics</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>ARI_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio_only</td>\n",
       "      <td>0.00</td>\n",
       "      <td>agglo</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.439324</td>\n",
       "      <td>0.893452</td>\n",
       "      <td>0.000211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>agglo</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.371191</td>\n",
       "      <td>0.992547</td>\n",
       "      <td>0.000187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>hybrid_alpha2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>agglo</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.204561</td>\n",
       "      <td>1.307274</td>\n",
       "      <td>0.000095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>hybrid_alpha1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>agglo</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.119826</td>\n",
       "      <td>1.925157</td>\n",
       "      <td>0.000050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>hybrid_alpha0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>agglo</td>\n",
       "      <td>k=4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2924</td>\n",
       "      <td>0.266422</td>\n",
       "      <td>1.298777</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      representation  alpha_lyrics algorithm params  n_clusters  noise_ratio  \\\n",
       "1         audio_only          0.00     agglo    k=4           4          0.0   \n",
       "21  hybrid_alpha0.25          0.25     agglo    k=4           4          0.0   \n",
       "81   hybrid_alpha2.0          2.00     agglo    k=4           4          0.0   \n",
       "61   hybrid_alpha1.0          1.00     agglo    k=4           4          0.0   \n",
       "41   hybrid_alpha0.5          0.50     agglo    k=4           4          0.0   \n",
       "\n",
       "    n_used_for_metrics  silhouette  davies_bouldin  ARI_language  \n",
       "1                 2924    0.439324        0.893452      0.000211  \n",
       "21                2924    0.371191        0.992547      0.000187  \n",
       "81                2924    0.204561        1.307274      0.000095  \n",
       "61                2924    0.119826        1.925157      0.000050  \n",
       "41                2924    0.266422        1.298777     -0.000011  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best DBSCAN:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>representation</th>\n",
       "      <th>alpha_lyrics</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>params</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>noise_ratio</th>\n",
       "      <th>n_used_for_metrics</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>ARI_language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>audio_only</td>\n",
       "      <td>0.00</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=0.6,min_samples=20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.264022</td>\n",
       "      <td>2152</td>\n",
       "      <td>0.355419</td>\n",
       "      <td>0.873377</td>\n",
       "      <td>0.003882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=2.0,min_samples=5</td>\n",
       "      <td>45</td>\n",
       "      <td>0.219904</td>\n",
       "      <td>2281</td>\n",
       "      <td>-0.148752</td>\n",
       "      <td>0.969375</td>\n",
       "      <td>0.003484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=1.2,min_samples=5</td>\n",
       "      <td>42</td>\n",
       "      <td>0.678181</td>\n",
       "      <td>941</td>\n",
       "      <td>0.078941</td>\n",
       "      <td>0.846278</td>\n",
       "      <td>0.003282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=1.5,min_samples=20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.650821</td>\n",
       "      <td>1021</td>\n",
       "      <td>0.250339</td>\n",
       "      <td>1.057510</td>\n",
       "      <td>0.003172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>hybrid_alpha0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>dbscan</td>\n",
       "      <td>eps=2.0,min_samples=10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.320793</td>\n",
       "      <td>1986</td>\n",
       "      <td>-0.112616</td>\n",
       "      <td>1.056036</td>\n",
       "      <td>0.002913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      representation  alpha_lyrics algorithm                  params  \\\n",
       "4         audio_only          0.00    dbscan  eps=0.6,min_samples=20   \n",
       "37  hybrid_alpha0.25          0.25    dbscan   eps=2.0,min_samples=5   \n",
       "31  hybrid_alpha0.25          0.25    dbscan   eps=1.2,min_samples=5   \n",
       "36  hybrid_alpha0.25          0.25    dbscan  eps=1.5,min_samples=20   \n",
       "38  hybrid_alpha0.25          0.25    dbscan  eps=2.0,min_samples=10   \n",
       "\n",
       "    n_clusters  noise_ratio  n_used_for_metrics  silhouette  davies_bouldin  \\\n",
       "4            4     0.264022                2152    0.355419        0.873377   \n",
       "37          45     0.219904                2281   -0.148752        0.969375   \n",
       "31          42     0.678181                 941    0.078941        0.846278   \n",
       "36           3     0.650821                1021    0.250339        1.057510   \n",
       "38          12     0.320793                1986   -0.112616        1.056036   \n",
       "\n",
       "    ARI_language  \n",
       "4       0.003882  \n",
       "37      0.003484  \n",
       "31      0.003282  \n",
       "36      0.003172  \n",
       "38      0.002913  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best-per-(rep,algo) to: C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_full\\medium_metrics_fixed_best.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, adjusted_rand_score\n",
    "\n",
    "# -----------------------\n",
    "# Paths (adjust if needed)\n",
    "# -----------------------\n",
    "DATA_ROOT = Path(r\"C:\\Users\\Atif\\Documents\\medium\\jamendolyrics_full\")  # <-- set to your downloaded dataset folder\n",
    "Z_AUDIO_PATH = DATA_ROOT / \"Z_audio.npy\"\n",
    "E64_PATH     = DATA_ROOT / \"E64.npy\"\n",
    "META_PATH    = DATA_ROOT / \"segment_meta_used.csv\"\n",
    "\n",
    "assert Z_AUDIO_PATH.exists(), f\"Missing: {Z_AUDIO_PATH}\"\n",
    "assert E64_PATH.exists(), f\"Missing: {E64_PATH}\"\n",
    "assert META_PATH.exists(), f\"Missing: {META_PATH}\"\n",
    "\n",
    "# -----------------------\n",
    "# Load data\n",
    "# -----------------------\n",
    "Z_audio = np.load(Z_AUDIO_PATH)         # (N, latent_dim)\n",
    "E64     = np.load(E64_PATH)             # (N, 64)\n",
    "meta    = pd.read_csv(META_PATH)        # must align row-by-row with arrays\n",
    "\n",
    "assert len(meta) == Z_audio.shape[0] == E64.shape[0], \"meta / Z_audio / E64 size mismatch!\"\n",
    "\n",
    "# Labels for ARI (language)\n",
    "y_lang = meta[\"language\"].astype(\"category\").cat.codes.values\n",
    "k = len(np.unique(y_lang))\n",
    "print(\"N:\", len(meta), \"| languages:\", k)\n",
    "\n",
    "# -----------------------\n",
    "# OPTIONAL FIX: cap segments per song (prevents clustering by song identity)\n",
    "# If your seg filenames are like: ...song012_line003_en.wav\n",
    "# Turn this on if ARI_language stays ~0 and you suspect clusters are grouping per song.\n",
    "# -----------------------\n",
    "CAP_PER_SONG = None  # e.g. 8 or 10; set None to disable\n",
    "\n",
    "if CAP_PER_SONG is not None:\n",
    "    # extract song_id from seg_path\n",
    "    def get_song_id(p):\n",
    "        m = re.search(r\"song(\\d+)\", str(p))\n",
    "        return m.group(1) if m else \"unknown\"\n",
    "    meta[\"song_id\"] = meta[\"seg_path\"].apply(get_song_id)\n",
    "\n",
    "    # sample at most CAP_PER_SONG rows per song\n",
    "    meta = (meta.groupby(\"song_id\", group_keys=False)\n",
    "                .apply(lambda g: g.sample(n=min(len(g), CAP_PER_SONG), random_state=42))\n",
    "                .reset_index(drop=True))\n",
    "\n",
    "    # filter arrays to match new meta order\n",
    "    idx = meta.index.values\n",
    "    Z_audio = Z_audio[idx]\n",
    "    E64 = E64[idx]\n",
    "    y_lang = meta[\"language\"].astype(\"category\").cat.codes.values\n",
    "    k = len(np.unique(y_lang))\n",
    "    print(\"After CAP_PER_SONG:\", len(meta), \"| languages:\", k)\n",
    "\n",
    "# -----------------------\n",
    "# Standardize each modality separately (KEY FIX)\n",
    "# -----------------------\n",
    "Za = StandardScaler().fit_transform(Z_audio)\n",
    "El = StandardScaler().fit_transform(E64)\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def safe_silhouette_db(Z, labels):\n",
    "    \"\"\"Return (silhouette, davies_bouldin) or (None, None) if not computable.\"\"\"\n",
    "    uniq = set(labels)\n",
    "    if len(uniq) < 2:\n",
    "        return None, None\n",
    "    # silhouette needs >=2 clusters and no empty clusters; DB needs >=2 clusters\n",
    "    try:\n",
    "        sil = silhouette_score(Z, labels)\n",
    "    except Exception:\n",
    "        sil = None\n",
    "    try:\n",
    "        db = davies_bouldin_score(Z, labels)\n",
    "    except Exception:\n",
    "        db = None\n",
    "    return sil, db\n",
    "\n",
    "def eval_dbscan(Z, eps, min_samples):\n",
    "    labels = DBSCAN(eps=eps, min_samples=min_samples).fit_predict(Z)\n",
    "    noise_ratio = float(np.mean(labels == -1))\n",
    "    # compute metrics only on non-noise points\n",
    "    mask = labels != -1\n",
    "    n_used = int(mask.sum())\n",
    "    # clusters among non-noise points\n",
    "    non_noise_clusters = set(labels[mask]) if n_used > 0 else set()\n",
    "    n_clusters = len(non_noise_clusters)\n",
    "\n",
    "    if n_used > 20 and n_clusters >= 2:\n",
    "        sil = silhouette_score(Z[mask], labels[mask])\n",
    "        db  = davies_bouldin_score(Z[mask], labels[mask])\n",
    "    else:\n",
    "        sil, db = None, None\n",
    "\n",
    "    ari = adjusted_rand_score(y_lang, labels)  # ARI can be computed with noise labels too\n",
    "    return labels, n_clusters, noise_ratio, n_used, sil, db, ari\n",
    "\n",
    "# -----------------------\n",
    "# Run experiments\n",
    "# -----------------------\n",
    "results = []\n",
    "\n",
    "# Representations: audio-only and hybrid with different lyric weights\n",
    "alpha_list = [0.0, 0.25, 0.5, 1.0, 2.0, 4.0]   # 0.0 = audio-only\n",
    "dbscan_eps_list = [0.6, 0.8, 1.0, 1.2, 1.5, 2.0]\n",
    "dbscan_min_samples_list = [5, 10, 20]\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    if alpha == 0.0:\n",
    "        Z = Za\n",
    "        rep_name = \"audio_only\"\n",
    "    else:\n",
    "        Z = np.concatenate([Za, alpha * El], axis=1)\n",
    "        rep_name = f\"hybrid_alpha{alpha}\"\n",
    "\n",
    "    # --- KMeans ---\n",
    "    labels = KMeans(n_clusters=k, random_state=42, n_init=\"auto\").fit_predict(Z)\n",
    "    sil, db = safe_silhouette_db(Z, labels)\n",
    "    ari = adjusted_rand_score(y_lang, labels)\n",
    "    results.append({\n",
    "        \"representation\": rep_name,\n",
    "        \"alpha_lyrics\": alpha,\n",
    "        \"algorithm\": \"kmeans\",\n",
    "        \"params\": f\"k={k}\",\n",
    "        \"n_clusters\": len(set(labels)),\n",
    "        \"noise_ratio\": 0.0,\n",
    "        \"n_used_for_metrics\": len(labels),\n",
    "        \"silhouette\": sil,\n",
    "        \"davies_bouldin\": db,\n",
    "        \"ARI_language\": ari\n",
    "    })\n",
    "\n",
    "    # --- Agglomerative ---\n",
    "    labels = AgglomerativeClustering(n_clusters=k).fit_predict(Z)\n",
    "    sil, db = safe_silhouette_db(Z, labels)\n",
    "    ari = adjusted_rand_score(y_lang, labels)\n",
    "    results.append({\n",
    "        \"representation\": rep_name,\n",
    "        \"alpha_lyrics\": alpha,\n",
    "        \"algorithm\": \"agglo\",\n",
    "        \"params\": f\"k={k}\",\n",
    "        \"n_clusters\": len(set(labels)),\n",
    "        \"noise_ratio\": 0.0,\n",
    "        \"n_used_for_metrics\": len(labels),\n",
    "        \"silhouette\": sil,\n",
    "        \"davies_bouldin\": db,\n",
    "        \"ARI_language\": ari\n",
    "    })\n",
    "\n",
    "    # --- DBSCAN sweep (best row will be chosen later) ---\n",
    "    for eps in dbscan_eps_list:\n",
    "        for ms in dbscan_min_samples_list:\n",
    "            labels, n_clusters, noise_ratio, n_used, sil, db, ari = eval_dbscan(Z, eps=eps, min_samples=ms)\n",
    "            results.append({\n",
    "                \"representation\": rep_name,\n",
    "                \"alpha_lyrics\": alpha,\n",
    "                \"algorithm\": \"dbscan\",\n",
    "                \"params\": f\"eps={eps},min_samples={ms}\",\n",
    "                \"n_clusters\": n_clusters,\n",
    "                \"noise_ratio\": noise_ratio,\n",
    "                \"n_used_for_metrics\": n_used,\n",
    "                \"silhouette\": sil,\n",
    "                \"davies_bouldin\": db,\n",
    "                \"ARI_language\": ari\n",
    "            })\n",
    "\n",
    "metrics = pd.DataFrame(results)\n",
    "\n",
    "# Save full table\n",
    "out_csv = DATA_ROOT / \"medium_metrics_fixed_full.csv\"\n",
    "metrics.to_csv(out_csv, index=False)\n",
    "print(\"Saved full metrics to:\", out_csv)\n",
    "\n",
    "# Show the best configurations (by ARI_language first, then silhouette)\n",
    "print(\"\\nTop 15 rows by ARI_language then silhouette:\")\n",
    "display(\n",
    "    metrics.sort_values([\"ARI_language\", \"silhouette\"], ascending=[False, False]).head(15)\n",
    ")\n",
    "\n",
    "# Also show best-per-algorithm for quick reporting\n",
    "best_kmeans = metrics[metrics[\"algorithm\"]==\"kmeans\"].sort_values(\"ARI_language\", ascending=False).head(5)\n",
    "best_agglo  = metrics[metrics[\"algorithm\"]==\"agglo\"].sort_values(\"ARI_language\", ascending=False).head(5)\n",
    "best_dbscan = metrics[metrics[\"algorithm\"]==\"dbscan\"].sort_values(\"ARI_language\", ascending=False).head(5)\n",
    "\n",
    "print(\"\\nBest KMeans:\")\n",
    "display(best_kmeans)\n",
    "\n",
    "print(\"\\nBest Agglo:\")\n",
    "display(best_agglo)\n",
    "\n",
    "print(\"\\nBest DBSCAN:\")\n",
    "display(best_dbscan)\n",
    "\n",
    "# OPTIONAL: Save a smaller \"report-ready\" CSV with the best row for each (representation, algorithm)\n",
    "best_rows = (metrics.sort_values([\"ARI_language\", \"silhouette\"], ascending=[False, False])\n",
    "                    .groupby([\"representation\",\"algorithm\"], as_index=False)\n",
    "                    .head(1))\n",
    "out_csv2 = DATA_ROOT / \"medium_metrics_fixed_best.csv\"\n",
    "best_rows.to_csv(out_csv2, index=False)\n",
    "print(\"Saved best-per-(rep,algo) to:\", out_csv2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (audio)",
   "language": "python",
   "name": "audio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
